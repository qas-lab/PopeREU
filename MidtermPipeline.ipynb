{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b2f2c899-2c6a-481e-bd53-70f7fb23eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install tensorflow\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "\n",
    "## imports for preprocessing\n",
    "!pip install -U scikit-learn\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('all')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#imports for sentiment analysis\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "#imports for model prediction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3ddeb6f-a27a-441b-bfda-70a5b4124514",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Accessing a CSV\n",
    "uploaded_zip = '/home/spope/EclipsePlatform/eclipse_platform.zip'\n",
    "extract_dir = '/home/spope/EclipsePlatform/extracted'\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "with zipfile.ZipFile(uploaded_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "csv_file = os.path.join(extract_dir, 'eclipse_platform.csv')\n",
    "fulldata = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86afeca9-4ac6-470e-96dc-4a0a7bcc3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "def SplitData(dataset):\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        trainset, testset = dataset[:train_size], dataset[train_size:]\n",
    "        return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9a6ea03-c0c6-4283-8fd2-92f6bbc61f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSet:\n",
    "    def CreateDuration(dataset):\n",
    "        dataset['Created_time'] = pd.to_datetime(dataset['Created_time'], utc=True)\n",
    "        dataset['Resolved_time'] = pd.to_datetime(dataset['Resolved_time'], utc=True)\n",
    "\n",
    "        # Convert to the desired format\n",
    "        dataset['Created_time2'] = dataset['Created_time'].dt.strftime('%m/%d/%Y %H:%M')\n",
    "        dataset['Resolved_time2'] = dataset['Resolved_time'].dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "        # Parse the formatted datetime strings back to datetime objects to ensure they are in the correct format\n",
    "        dataset['Created_time2'] = pd.to_datetime(dataset['Created_time2'], format='%m/%d/%Y %H:%M')\n",
    "        dataset['Resolved_time2'] = pd.to_datetime(dataset['Resolved_time2'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "        # Calculate the duration in hours\n",
    "        dataset['Duration'] = dataset['Resolved_time2'] - dataset['Created_time2']\n",
    "        dataset['Duration_hours'] = dataset['Duration'].dt.total_seconds() / 3600\n",
    "\n",
    "        # Drop the intermediate columns\n",
    "        dataset.drop(['Created_time2', 'Resolved_time2', 'Duration'], axis=1, inplace=True)\n",
    "    def CreateTimeLabel(dataset):\n",
    "        mean_duration_hours = dataset['Duration_hours'].mean()\n",
    "\n",
    "        # Apply labels based on the mean duration\n",
    "        dataset.loc[:, 'TimeLabel'] = dataset['Duration_hours'].apply(lambda x: 'long' if x >= mean_duration_hours else 'short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a74834c-431a-4201-9709-447a80e9e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def RemoveStopWords(dataset):\n",
    "        #making all the items in the descriptions columns lower\n",
    "        dataset['Description'] = dataset['Description'].str.lower()\n",
    "        # Define stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "         # Remove stop words\n",
    "        for index, row in dataset.iterrows():\n",
    "            # Check if the 'Description' is not NaN\n",
    "            if isinstance(row['Description'], str):\n",
    "                words = row['Description'].split()\n",
    "                final_tokens = [word for word in words if word not in stop_words]\n",
    "                dataset.at[index, 'Description'] = ' '.join(final_tokens)\n",
    "    \n",
    "        return dataset\n",
    "    def Lemmitization(dataset):\n",
    "        # Initialize the WordNet Lemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        # Function to lemmatize a sentence\n",
    "        def lemmatize_sentence(sentence):\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "            lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]  # Lemmatize verbs (default)\n",
    "            return ' '.join(lemmatized_words)\n",
    "        dataset['Description'] = dataset['Description'].astype(str)  # Convert all to strings\n",
    "\n",
    "        # Apply lemmatization to each row in the 'Description' column\n",
    "        dataset['Description'] = dataset['Description'].apply(lemmatize_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dae001fe-04ec-4dbe-9a50-431a11e804fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "          if treebank_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "          elif treebank_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "          elif treebank_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "          elif treebank_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "          else:\n",
    "            return None\n",
    "    # Function to calculate sentiment scores\n",
    "    def CalculateSentimentScores(description):\n",
    "        tokens = word_tokenize(description)\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        \n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        token_count = 0\n",
    "    \n",
    "        for word, tag in tagged_tokens:\n",
    "            wn_tag = SentimentAnalysis.get_wordnet_pos(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "        \n",
    "            synsets = list(swn.senti_synsets(word, wn_tag))\n",
    "            if not synsets:\n",
    "                continue\n",
    "        \n",
    "            # Use the first synset for simplicity\n",
    "            synset = synsets[0]\n",
    "            pos_score += synset.pos_score()\n",
    "            neg_score += synset.neg_score()\n",
    "            token_count += 1\n",
    "    \n",
    "        # Normalize scores by the number of tokens\n",
    "        if token_count > 0:\n",
    "            pos_score /= token_count\n",
    "            neg_score /= token_count\n",
    "            return pos_score, neg_score\n",
    "    # Apply sentiment score calculation to each description\n",
    "    def CreatePosNegColumns(dataset): \n",
    "        dataset[['Pos_Score', 'Neg_Score']] = dataset['Description'].apply(lambda x: pd.Series(SentimentAnalysis.CalculateSentimentScores(x)))\n",
    "    #Creating a column for Emotion (Positive or Negative)\n",
    "    def EmotionColumn(dataset):\n",
    "        #Creating a column for binary emotion (positive or negative)\n",
    "        dataset['Emotion'] = dataset['Pos_Score'] - dataset['Neg_Score']\n",
    "    \n",
    "        # Assign labels based on the difference\n",
    "        dataset['Emotion'] = dataset['Emotion'].apply(lambda x: 'positive' if x > 0 else 'negative')\n",
    "    def EmotionalityColumn(dataset):\n",
    "        dataset['Emotionality'] = dataset['Pos_Score']+ dataset['Neg_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c026c439-d29f-43c3-b110-0e76d10b88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def ModelTest(df, input_column, target_column, vectorizer_path, model_path):\n",
    "    # Concatenate input columns to form the feature set\n",
    "    X = df[input_column].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "    y = df[target_column]  # Target variable\n",
    "    \n",
    "    # Load the pre-trained model and vectorizer\n",
    "    model = joblib.load(model_path)\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    \n",
    "    # Vectorize the text data\n",
    "    X_vec = vectorizer.transform(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_vec)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    f1 = f1_score(y, predictions, average='weighted')\n",
    "    precision = precision_score(y, predictions, average='weighted')\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e034fc6c-f796-47e6-bd1a-713aa0ceddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "F1 Score: 0.65\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "def pipelineTimeLabel(dataset, model):\n",
    "    trainset, testset = SplitData(dataset)\n",
    "    TimeSet.CreateDuration(testset)\n",
    "    TimeSet.CreateTimeLabel(testset)\n",
    "    Preprocessing.RemoveStopWords(testset)\n",
    "    Preprocessing.Lemmitization(testset)\n",
    "    SentimentAnalysis.CreatePosNegColumns(testset)\n",
    "    SentimentAnalysis.EmotionColumn(testset)\n",
    "    SentimentAnalysis.EmotionalityColumn(testset)\n",
    "    ModelTest(testset, 'Emotion', 'TimeLabel', model_path= model)\n",
    "    testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4918e3ab-e5b5-405d-ac86-80442fe4de96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "F1 Score: 0.65\n",
      "Precision: 0.567030853061567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spope/anaconda3/envs/reu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "testset2 = testset[testset['Resolution'].str.contains('FIXED', na=False)]\n",
    "ModelTest(testset2, 'Emotion', 'TimeLabel', model_path= 'MLPmodelFixedTime.joblib', vectorizer_path='vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce98ed73-a33e-4274-8f08-3ad3fb3959ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "F1 Score: 0.65\n",
      "Precision: 0.5744522102290915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spope/anaconda3/envs/reu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "ModelTest(testset, 'Emotion', 'TimeLabel', model_path= 'MLPmodelTimeLabel.joblib', vectorizer_path='vectorizer2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cb624700-1639-4734-8be9-a00886a34194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "F1 Score: 0.66\n",
      "Precision: 0.7373152526811652\n"
     ]
    }
   ],
   "source": [
    "ModelTest(testset, ['Priority', 'Emotion'], 'TimeLabel', model_path= 'MLPmodelTimeLabelPriority.joblib', vectorizer_path='vectorizer3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86bd21f1-eb15-4afb-9eaf-e0acbc6751bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "F1 Score: 0.66\n",
      "Precision: 0.7373152526811652\n"
     ]
    }
   ],
   "source": [
    "ModelTest(testset, ['Priority', 'Emotion','Emotionality'], 'TimeLabel', model_path= 'MLPmodelTimeLabelPriorityEmotionality.joblib', vectorizer_path='vectorizer4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cdef4-2a26-480c-b912-fad6fd3bd81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
