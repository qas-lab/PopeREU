{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e74be834-1bef-4a13-9f88-6d25a770bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports for the machine learning testing\n",
    "%%capture\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "!pip install torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.read_csv(zipfile.ZipFile('sentiAnalysis.zip').open('sentiAnalysis.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16e5360d-d01c-407f-9362-f61798d99fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a column for eventual label (FIXED or NOTFIXED)\n",
    "def categorize_label(label):\n",
    "    if 'FIXED' in label.upper():  # Convert to uppercase and check for 'FIXED'\n",
    "        return 'FIXED'\n",
    "    else:\n",
    "        return 'NOTFIXED'\n",
    "\n",
    "df['eventual'] = df['Resolution'].apply(categorize_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f65a36b-7846-4965-b005-684484b21e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5696880733944955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.76      0.16      0.26      6573\n",
      "    NOTFIXED       0.55      0.95      0.70      7052\n",
      "\n",
      "    accuracy                           0.57     13625\n",
      "   macro avg       0.65      0.56      0.48     13625\n",
      "weighted avg       0.65      0.57      0.49     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Creating a function to train a naive bayes\n",
    "def naive_bayes(df, feature_cols, target_col, test_size=0.2, random_state=42):\n",
    "\n",
    "    #if looking for time only look at the columns that turned out to be fixed \n",
    "    if 'label' in target_col:\n",
    "        df = df[df['Resolution'].str.contains('FIXED', na=False)]\n",
    "\n",
    "    # Fill missing values in feature columns\n",
    "    df[feature_cols] = df[feature_cols].fillna(' ')\n",
    "\n",
    "    # Combine feature columns into a single column for vectorization\n",
    "    df['combined'] = df[feature_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    # Encode the combined text column\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['combined'])\n",
    "\n",
    "    # Encode the target column\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Ensure X and y have the same length\n",
    "    assert X.shape[0] == len(y), \"Features and labels have inconsistent lengths.\"\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize and train the Naive Bayes model\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3065b31-fb45-4038-b1fb-76a9b7fe99c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5696880733944955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.76      0.16      0.26      6573\n",
      "    NOTFIXED       0.55      0.95      0.70      7052\n",
      "\n",
      "    accuracy                           0.57     13625\n",
      "   macro avg       0.65      0.56      0.48     13625\n",
      "weighted avg       0.65      0.57      0.49     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##creating a function to train a SVM model \n",
    "def train_svm(df, feature_cols, target_col, test_size=0.2, random_state=42):\n",
    "\n",
    "    #if testing for eventual time to fix then \n",
    "    if 'label' in target_col:\n",
    "        df = df[df['Resolution'].str.contains('FIXED', na=False)]\n",
    "\n",
    "    # Fill missing values in feature columns\n",
    "    df[feature_cols] = df[feature_cols].fillna(' ')\n",
    "\n",
    "    # Combine feature columns into a single column for vectorization\n",
    "    df['combined'] = df[feature_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    # Encode the combined text column\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['combined'])\n",
    "\n",
    "    # Encode the target column\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Ensure X and y have the same length\n",
    "    assert X.shape[0] == len(y), \"Features and labels have inconsistent lengths.\"\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize and train the SVM model\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "trial1 = train_svm(df, feature_cols=['emotion', 'Priority'], target_col='eventual')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50901cef-20d7-4e27-8e3c-b0fedd4814d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5696880733944955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.76      0.16      0.26      6573\n",
      "    NOTFIXED       0.55      0.95      0.70      7052\n",
      "\n",
      "    accuracy                           0.57     13625\n",
      "   macro avg       0.65      0.56      0.48     13625\n",
      "weighted avg       0.65      0.57      0.49     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial1 = train_naive_bayes(df, feature_cols = ['emotion', 'Priority'], target_col = 'eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aa31ebc-d359-4f27-8e53-17cb71bb8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5639633027522936\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.57      0.40      0.47      6573\n",
      "    NOTFIXED       0.56      0.71      0.63      7052\n",
      "\n",
      "    accuracy                           0.56     13625\n",
      "   macro avg       0.56      0.56      0.55     13625\n",
      "weighted avg       0.56      0.56      0.55     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial2 = train_naive_bayes(df, feature_cols = ['emotion', 'Priority', 'Emotionality'], target_col = 'eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2ae19ee-c3a0-4046-87c4-7afe5a7514b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5696880733944955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.76      0.16      0.26      6573\n",
      "    NOTFIXED       0.55      0.95      0.70      7052\n",
      "\n",
      "    accuracy                           0.57     13625\n",
      "   macro avg       0.65      0.56      0.48     13625\n",
      "weighted avg       0.65      0.57      0.49     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial2 = train_naive_bayes(df, feature_cols = ['Priority'], target_col = 'eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa1ec66-3086-407d-9c01-4d6edba0e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5069357798165137\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.49      0.49      0.49      6573\n",
      "    NOTFIXED       0.52      0.52      0.52      7052\n",
      "\n",
      "    accuracy                           0.51     13625\n",
      "   macro avg       0.51      0.51      0.51     13625\n",
      "weighted avg       0.51      0.51      0.51     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial2 = train_naive_bayes(df, feature_cols = ['emotion', 'Emotionality'], target_col = 'eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7341dc94-45ba-4693-beee-331e5ae1a2fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5544954128440367\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.52      0.93      0.67      6573\n",
      "    NOTFIXED       0.76      0.20      0.32      7052\n",
      "\n",
      "    accuracy                           0.55     13625\n",
      "   macro avg       0.64      0.57      0.50     13625\n",
      "weighted avg       0.64      0.55      0.49     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial2 = train_naive_bayes(df, feature_cols = ['Description','Priority', 'Emotionality', 'label'], target_col = 'eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3bd1086-7665-472a-bfc2-8cfca37c646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5067155963302752\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.49      0.48      0.48      6573\n",
      "    NOTFIXED       0.52      0.53      0.53      7052\n",
      "\n",
      "    accuracy                           0.51     13625\n",
      "   macro avg       0.51      0.51      0.51     13625\n",
      "weighted avg       0.51      0.51      0.51     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial2 = train_naive_bayes(df, feature_cols = ['Emotionality'], target_col = 'eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a63084d-77a1-4fea-aa00-6732529f97c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149189/2617318525.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[feature_cols] = df[feature_cols].fillna(' ')\n",
      "/tmp/ipykernel_149189/2617318525.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined'] = df[feature_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8303708243947288\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        long       0.39      0.03      0.06      1087\n",
      "       short       0.84      0.99      0.91      5439\n",
      "\n",
      "    accuracy                           0.83      6526\n",
      "   macro avg       0.61      0.51      0.48      6526\n",
      "weighted avg       0.76      0.83      0.77      6526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial2 = train_naive_bayes(df, feature_cols = ['emotion', 'Priority', 'Emotionality'], target_col = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b436a213-fa81-4b24-8c6d-93884857c726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5696880733944955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.76      0.16      0.26      6573\n",
      "    NOTFIXED       0.55      0.95      0.70      7052\n",
      "\n",
      "    accuracy                           0.57     13625\n",
      "   macro avg       0.65      0.56      0.48     13625\n",
      "weighted avg       0.65      0.57      0.49     13625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial1 = train_svm(df, feature_cols=['Priority'], target_col='eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f93f94-d5a3-4834-8cd8-ee4f482cacb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spope/anaconda3/envs/reu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/spope/anaconda3/envs/reu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8557064220183487\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.00      0.00      0.00       427\n",
      "          P2       0.00      0.00      0.00       935\n",
      "          P3       0.86      1.00      0.92     11659\n",
      "          P4       0.00      0.00      0.00       377\n",
      "          P5       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.86     13625\n",
      "   macro avg       0.17      0.20      0.18     13625\n",
      "weighted avg       0.73      0.86      0.79     13625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spope/anaconda3/envs/reu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "trial1 = train_svm(df, feature_cols=['emotion'], target_col='Priority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57e1dac1-6cfd-4d61-a8c2-31021cb2d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6289908256880734\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.60      0.70      0.64      6573\n",
      "    NOTFIXED       0.67      0.56      0.61      7052\n",
      "\n",
      "    accuracy                           0.63     13625\n",
      "   macro avg       0.63      0.63      0.63     13625\n",
      "weighted avg       0.63      0.63      0.63     13625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6289908256880734,\n",
       " '              precision    recall  f1-score   support\\n\\n       FIXED       0.60      0.70      0.64      6573\\n    NOTFIXED       0.67      0.56      0.61      7052\\n\\n    accuracy                           0.63     13625\\n   macro avg       0.63      0.63      0.63     13625\\nweighted avg       0.63      0.63      0.63     13625\\n')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_svm(df, feature_cols=['Component', 'Title', 'Description','emotion','Emotionality'], target_col='eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d92b098-f15a-4cc1-9814-1105110fdf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5547155963302752\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FIXED       0.52      0.93      0.67      6573\n",
      "    NOTFIXED       0.76      0.21      0.32      7052\n",
      "\n",
      "    accuracy                           0.55     13625\n",
      "   macro avg       0.64      0.57      0.50     13625\n",
      "weighted avg       0.64      0.55      0.49     13625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5547155963302752,\n",
       " '              precision    recall  f1-score   support\\n\\n       FIXED       0.52      0.93      0.67      6573\\n    NOTFIXED       0.76      0.21      0.32      7052\\n\\n    accuracy                           0.55     13625\\n   macro avg       0.64      0.57      0.50     13625\\nweighted avg       0.64      0.55      0.49     13625\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_naive_bayes(df, feature_cols=['Component', 'Title', 'Description','emotion','Emotionality'], target_col='eventual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92bb7a5-17b7-41bd-825c-ee9ddbf615b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 8\n",
      "CUDA device name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:6\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m model2\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(6))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:6\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae0d41-d49c-43c1-a32e-a5c8afe73ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
